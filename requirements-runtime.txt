# Minimal runtime dependencies for inference service
# Use this for production images to reduce footprint

# Core
torch>=2.0.0
numpy>=1.24.0
pyyaml>=6.0

# API
fastapi>=0.100.0
uvicorn>=0.23.0
pydantic>=2.0.0

# Optional: enable if using NLTK in runtime
# nltk>=3.8.0

# Optional: only if you build vocab at runtime
# pandas>=2.0.0